{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bdff7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# 20개의 토픽을 가진 11,314개 뉴스기사 데이터셋 \n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                            remove=('headers','footers','quotes'))\n",
    "documents = dataset.data\n",
    "len(documents) # 문서 수 총 11,314개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606ced2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target_names\n",
    "# 20개의 토픽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b39444c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "{\"hasn't\", 'i', \"should've\", 'having', 'ain', 'aren', \"won't\", 'myself', \"you'll\", 'my', 'ours', 'where', 'up', 'wouldn', 'been', 'out', 'we', 'what', 'during', 'had', 'off', 've', \"mightn't\", 'shouldn', 'you', 'its', 'needn', 'itself', 'hadn', 'won', \"it's\", 'at', 'once', 'your', 's', 'yours', 'to', 'there', 'whom', 'here', \"didn't\", 'isn', 'about', 'which', 'have', \"that'll\", 'now', 'both', 'does', 'each', 'these', \"you'd\", 'under', 'them', 'themselves', 'the', 'himself', 'me', 'no', 'herself', 'hasn', 'their', 'than', \"she's\", 'do', 'very', 'after', 'a', 'all', 'y', 'until', 'because', 'can', \"mustn't\", 'doing', 'against', 'over', 'further', 'through', 'he', 'wasn', 'but', 'of', 'should', 'if', 'by', 'before', 'she', 'for', 'with', 'him', 'they', 'when', 'd', 'o', 'ma', 'yourselves', 'why', \"wouldn't\", \"you're\", 'was', 'on', 'more', 'ourselves', 'it', 'that', 'down', 'below', 'm', 'yourself', 't', 'haven', \"haven't\", 'being', 'not', 'while', 'weren', 'own', \"don't\", \"shan't\", \"aren't\", 'theirs', 'any', 'so', 'mightn', 'in', 'same', 'and', 'above', \"needn't\", 'between', 'will', 'am', \"doesn't\", 'doesn', 'some', \"you've\", \"isn't\", 'into', 're', 'our', \"weren't\", 'nor', 'were', 'who', 'has', 'shan', 'mustn', 'then', 'is', 'this', 'again', 'as', 'didn', 'such', \"shouldn't\", 'few', \"couldn't\", 'too', 'how', 'her', 'hers', 'are', \"wasn't\", 'most', 'be', 'just', 'only', 'his', 'don', 'or', 'did', 'those', 'couldn', \"hadn't\", 'other', 'from', 'an', 'll'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "print(len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582767c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\answl\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "\n",
    "# 알파벳 이외 문자 제거 \n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
    "\n",
    "# 길이가 3 이하인 문자 제거\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "\n",
    "# 소문자로 바꾸기 \n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n",
    "\n",
    "# 불용어 제거 \n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if w not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72c07c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1000)\n",
      "  (0, 663)\t0.12579678422048154\n",
      "  (0, 443)\t0.16044476823657502\n",
      "  (0, 495)\t0.11696449109610255\n",
      "  (0, 72)\t0.1314390240262082\n",
      "  (0, 514)\t0.13329247332522626\n",
      "  (0, 366)\t0.12802751239278712\n",
      "  (0, 716)\t0.16076629236479573\n",
      "  (0, 815)\t0.1860578624833558\n",
      "  (0, 733)\t0.1650860017284942\n",
      "  (0, 153)\t0.15949923481234501\n",
      "  (0, 731)\t0.16276677998135436\n",
      "  (0, 712)\t0.12950552246491173\n",
      "  (0, 894)\t0.08872588336284767\n",
      "  (0, 475)\t0.16965522872699737\n",
      "  (0, 230)\t0.17232789867083467\n",
      "  (0, 710)\t0.1673880130842719\n",
      "  (0, 986)\t0.12271896638163997\n",
      "  (0, 437)\t0.34750677684180636\n",
      "  (0, 530)\t0.66718686100149\n",
      "  (0, 842)\t0.15408639160668727\n",
      "  (0, 850)\t0.15858098023021014\n",
      "  (0, 868)\t0.11258683260681689\n",
      "  (1, 336)\t0.21610968006327091\n",
      "  (1, 580)\t0.2090150657514671\n",
      "  (1, 837)\t0.1705873334780892\n",
      "  :\t:\n",
      "  (11313, 162)\t0.12246744316703376\n",
      "  (11313, 186)\t0.15901931792515023\n",
      "  (11313, 911)\t0.1696585245733748\n",
      "  (11313, 97)\t0.14464380399033505\n",
      "  (11313, 946)\t0.14195612945068303\n",
      "  (11313, 515)\t0.1445563959897329\n",
      "  (11313, 694)\t0.13924844887437873\n",
      "  (11313, 932)\t0.10643989468958723\n",
      "  (11313, 997)\t0.23080563157336156\n",
      "  (11313, 728)\t0.13744262026929388\n",
      "  (11313, 714)\t0.16398850940417123\n",
      "  (11313, 822)\t0.16026323590534008\n",
      "  (11313, 589)\t0.15494318040653263\n",
      "  (11313, 133)\t0.14747580234200475\n",
      "  (11313, 470)\t0.16730665428945277\n",
      "  (11313, 365)\t0.2923136436479072\n",
      "  (11313, 747)\t0.10820839951849766\n",
      "  (11313, 996)\t0.12043836958282284\n",
      "  (11313, 113)\t0.14293839781540874\n",
      "  (11313, 127)\t0.1409241655992228\n",
      "  (11313, 953)\t0.10614064808032307\n",
      "  (11313, 456)\t0.08529989478770372\n",
      "  (11313, 481)\t0.08171430544788967\n",
      "  (11313, 9)\t0.1248689747941886\n",
      "  (11313, 300)\t0.15730189638551084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                            max_features=1000, # 단어 천개만 추출 \n",
    "                            max_df=0.5,\n",
    "                            smooth_idf=True)\n",
    "\n",
    "x = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "\n",
    "print(x.shape)\n",
    "# 11314개 문서, 1000개 단어 \n",
    "# 문서-단어 행렬 (DTM)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fecb0395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.20185845, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.23080563, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cbf170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 뉴스 토픽 총 20개 --> 토픽 모델링 \n",
    "svd_model = TruncatedSVD(n_components=20, # 상위 20개 특이값만\n",
    "                        algorithm='randomized',\n",
    "                        n_iter=100,\n",
    "                        random_state=122)\n",
    "\n",
    "svd_model.fit(x)\n",
    "\n",
    "svd_model.components_.shape\n",
    "# (20, 1000) : Vt 행렬 크기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75568269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.67063607,  9.94205981,  8.2061179 ,  7.91123934,  7.62272699,\n",
       "        7.31738569,  7.14730728,  6.91125279,  6.86782698,  6.73282362,\n",
       "        6.62603555,  6.53236743,  6.48971321,  6.37002011,  6.22550494,\n",
       "        6.18079939,  6.08149194,  5.98740576,  5.94626197,  5.90237972])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.singular_values_\n",
    "# 20개의 특이값 (내림차순)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c5cb91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01470105,  0.05015495,  0.02134726, ...,  0.07877501,\n",
       "         0.01438332,  0.01790281],\n",
       "       [-0.00533386,  0.01656067, -0.01645455, ..., -0.06350291,\n",
       "        -0.01065062, -0.01901778],\n",
       "       [ 0.00172532, -0.00376834, -0.01802467, ...,  0.05883215,\n",
       "         0.02633999,  0.02240509],\n",
       "       ...,\n",
       "       [-0.01120005,  0.00433952,  0.00278103, ...,  0.02077478,\n",
       "        -0.00121335,  0.00046334],\n",
       "       [ 0.00173909,  0.01507013,  0.01111258, ..., -0.0908733 ,\n",
       "        -0.00135117, -0.00540481],\n",
       "       [ 0.00191827, -0.03624131, -0.00567909, ...,  0.03611942,\n",
       "        -0.01425782, -0.00352156]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5407b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['ability', 'able', 'accept', 'access', 'according', 'account', 'action', 'actions', 'actual', 'actually', 'added', 'addition', 'additional', 'address', 'administration', 'advance', 'advice', 'agencies', 'agree', 'algorithm', 'allow', 'allowed', 'allows', 'amendment', 'america', 'american', 'americans', 'analysis', 'angeles', 'anonymous', 'answer', 'answers', 'anti', 'anybody', 'apparently', 'appear', 'appears', 'apple', 'application', 'applications', 'apply', 'appreciate', 'appreciated', 'approach', 'appropriate', 'april', 'arab', 'archive', 'area', 'areas', 'argument', 'arguments', 'armenia', 'armenian', 'armenians', 'arms', 'army', 'article', 'articles', 'asked', 'asking', 'assume', 'assuming', 'atheism', 'atheists', 'attack', 'attempt', 'author', 'authority', 'available', 'average', 'avoid', 'away', 'background', 'base', 'baseball', 'based', 'basic', 'basically', 'basis', 'begin', 'beginning', 'belief', 'beliefs', 'believe', 'best', 'better', 'bible', 'bike', 'bios', 'bits', 'black', 'block', 'blood', 'blue', 'board', 'body', 'book', 'books', 'boston', 'bought', 'break', 'bring', 'brought', 'build', 'building', 'built', 'business', 'cable', 'california', 'called', 'calling', 'calls', 'came', 'canada', 'card', 'cards', 'care', 'carry', 'cars', 'case', 'cases', 'cause', 'center', 'certain', 'certainly', 'chance', 'change', 'changed', 'changes', 'char', 'character', 'cheap', 'check', 'chicago', 'child', 'children', 'chip', 'chips', 'choice', 'choose', 'christ', 'christian', 'christianity', 'christians', 'church', 'citizens', 'city', 'civil', 'claim', 'claims', 'class', 'clear', 'clearly', 'clinton', 'clipper', 'clock', 'close', 'code', 'color', 'colorado', 'colors', 'come', 'comes', 'coming', 'command', 'comment', 'comments', 'commercial', 'committee', 'common', 'communications', 'community', 'comp', 'companies', 'company', 'compatible', 'complete', 'completely', 'computer', 'conclusion', 'condition', 'conference', 'congress', 'connection', 'consider', 'considered', 'considering', 'contact', 'contains', 'context', 'continue', 'contrib', 'control', 'controller', 'convert', 'copies', 'copy', 'correct', 'cost', 'costs', 'count', 'countries', 'country', 'couple', 'course', 'court', 'cover', 'create', 'created', 'crime', 'criminals', 'cross', 'current', 'currently', 'data', 'date', 'dave', 'david', 'days', 'dead', 'deal', 'death', 'decided', 'decision', 'default', 'defense', 'define', 'deleted', 'department', 'described', 'description', 'design', 'designed', 'details', 'detroit', 'developed', 'development', 'device', 'devices', 'died', 'difference', 'different', 'difficult', 'digital', 'direct', 'directly', 'directory', 'discussion', 'disease', 'disk', 'disks', 'display', 'distribution', 'division', 'doctor', 'door', 'double', 'doubt', 'draw', 'drive', 'driver', 'drivers', 'drives', 'driving', 'drug', 'drugs', 'earlier', 'early', 'earth', 'easily', 'east', 'easy', 'education', 'effect', 'effective', 'effort', 'electronic', 'email', 'encryption', 'energy', 'enforcement', 'engine', 'entire', 'entry', 'environment', 'equipment', 'error', 'errors', 'escrow', 'especially', 'event', 'events', 'evidence', 'exactly', 'example', 'excellent', 'exist', 'existence', 'exists', 'expect', 'expected', 'expensive', 'experience', 'explain', 'export', 'extra', 'face', 'fact', 'fairly', 'faith', 'fall', 'false', 'family', 'fast', 'faster', 'father', 'features', 'federal', 'feel', 'field', 'figure', 'file', 'files', 'final', 'finally', 'fine', 'firearms', 'floppy', 'folks', 'follow', 'following', 'font', 'fonts', 'food', 'force', 'forget', 'form', 'format', 'forward', 'free', 'freedom', 'friend', 'friends', 'fully', 'function', 'functions', 'future', 'game', 'games', 'gave', 'general', 'generally', 'genocide', 'germany', 'gets', 'getting', 'given', 'gives', 'giving', 'goal', 'goals', 'goes', 'going', 'gone', 'good', 'government', 'graphics', 'great', 'greatly', 'greek', 'ground', 'group', 'groups', 'guess', 'guns', 'guys', 'half', 'hand', 'handle', 'hands', 'happen', 'happened', 'happens', 'happy', 'hard', 'hardware', 'head', 'health', 'hear', 'heard', 'heaven', 'held', 'hell', 'hello', 'help', 'high', 'higher', 'history', 'hockey', 'hold', 'holy', 'home', 'hope', 'hours', 'house', 'human', 'idea', 'ideas', 'image', 'images', 'imagine', 'important', 'include', 'included', 'includes', 'including', 'increase', 'independent', 'individual', 'info', 'information', 'input', 'inside', 'installed', 'instead', 'institute', 'insurance', 'intended', 'interested', 'interesting', 'interface', 'internal', 'international', 'internet', 'involved', 'israel', 'israeli', 'issue', 'issues', 'james', 'jesus', 'jewish', 'jews', 'jobs', 'john', 'jpeg', 'kept', 'keyboard', 'keys', 'kill', 'killed', 'killing', 'kind', 'king', 'knew', 'know', 'knowledge', 'known', 'knows', 'lack', 'land', 'language', 'large', 'late', 'later', 'latest', 'launch', 'laws', 'lead', 'league', 'learn', 'leave', 'left', 'legal', 'letter', 'level', 'library', 'license', 'life', 'light', 'like', 'likely', 'limited', 'line', 'lines', 'list', 'little', 'live', 'lives', 'living', 'local', 'logic', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lord', 'lost', 'lots', 'love', 'lower', 'lunar', 'machine', 'machines', 'magazine', 'mail', 'mailing', 'main', 'major', 'majority', 'make', 'makes', 'making', 'manager', 'manual', 'march', 'mark', 'market', 'mass', 'master', 'material', 'matter', 'matthew', 'maybe', 'mean', 'meaning', 'means', 'media', 'medical', 'member', 'members', 'memory', 'mention', 'mentioned', 'message', 'messages', 'method', 'michael', 'middle', 'mike', 'miles', 'military', 'million', 'mind', 'minutes', 'misc', 'mission', 'mode', 'model', 'models', 'modem', 'modern', 'money', 'monitor', 'month', 'months', 'moon', 'moral', 'morning', 'mother', 'motif', 'mouse', 'multi', 'multiple', 'muslim', 'names', 'nasa', 'national', 'natural', 'nature', 'near', 'necessary', 'need', 'needed', 'needs', 'network', 'news', 'newsgroup', 'nice', 'night', 'normal', 'north', 'note', 'nuclear', 'null', 'number', 'numbers', 'object', 'objective', 'obvious', 'obviously', 'offer', 'offers', 'office', 'official', 'ones', 'open', 'operation', 'opinion', 'opinions', 'option', 'options', 'orbit', 'order', 'organization', 'original', 'output', 'outside', 'package', 'page', 'paid', 'pain', 'paper', 'particular', 'particularly', 'parts', 'party', 'pass', 'passed', 'past', 'patients', 'paul', 'peace', 'people', 'perfect', 'performance', 'period', 'person', 'personal', 'peter', 'phone', 'physical', 'pick', 'picture', 'pittsburgh', 'place', 'places', 'plan', 'play', 'played', 'player', 'players', 'playing', 'plus', 'point', 'points', 'police', 'policy', 'political', 'poor', 'population', 'port', 'position', 'possible', 'possibly', 'post', 'posted', 'posting', 'posts', 'postscript', 'power', 'practice', 'present', 'president', 'press', 'pretty', 'prevent', 'previous', 'price', 'print', 'printer', 'privacy', 'private', 'probably', 'problem', 'problems', 'process', 'processing', 'produce', 'product', 'products', 'program', 'programming', 'programs', 'project', 'protect', 'protection', 'prove', 'provide', 'provided', 'provides', 'public', 'published', 'purpose', 'quality', 'question', 'questions', 'quite', 'quote', 'radio', 'range', 'rate', 'rates', 'read', 'reading', 'real', 'reality', 'realize', 'really', 'reason', 'reasonable', 'reasons', 'receive', 'received', 'recent', 'recently', 'record', 'reference', 'references', 'regarding', 'regular', 'related', 'release', 'religion', 'religious', 'remember', 'remote', 'reply', 'report', 'reported', 'reports', 'request', 'require', 'required', 'requires', 'research', 'resource', 'resources', 'respect', 'response', 'rest', 'result', 'results', 'return', 'right', 'rights', 'risk', 'road', 'robert', 'room', 'round', 'rule', 'rules', 'running', 'runs', 'russia', 'russian', 'safe', 'safety', 'said', 'sale', 'satellite', 'save', 'saying', 'says', 'school', 'science', 'scientific', 'screen', 'scsi', 'search', 'season', 'second', 'secret', 'section', 'secure', 'security', 'seen', 'self', 'sell', 'send', 'sense', 'sent', 'serial', 'series', 'seriously', 'server', 'service', 'services', 'setting', 'shall', 'shipping', 'short', 'shot', 'shows', 'shuttle', 'signal', 'similar', 'simple', 'simply', 'single', 'site', 'sites', 'situation', 'size', 'slow', 'small', 'smith', 'social', 'society', 'software', 'sold', 'soldiers', 'solution', 'somebody', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'source', 'sources', 'south', 'soviet', 'space', 'speak', 'special', 'specific', 'specifically', 'speed', 'spirit', 'stand', 'standard', 'standards', 'start', 'started', 'starting', 'state', 'stated', 'statement', 'states', 'station', 'stay', 'step', 'stephanopoulos', 'steve', 'stop', 'story', 'stream', 'street', 'strong', 'studies', 'study', 'stuff', 'stupid', 'subject', 'suggest', 'suggestions', 'summer', 'supply', 'support', 'supported', 'supports', 'suppose', 'supposed', 'sure', 'surface', 'suspect', 'switch', 'systems', 'table', 'taken', 'takes', 'taking', 'talk', 'talking', 'tape', 'team', 'teams', 'technical', 'technology', 'tell', 'term', 'terms', 'test', 'text', 'thank', 'thanks', 'theory', 'thing', 'things', 'think', 'thinking', 'thought', 'time', 'times', 'title', 'today', 'told', 'took', 'tools', 'toronto', 'total', 'town', 'trade', 'traffic', 'transfer', 'tried', 'trouble', 'true', 'trust', 'truth', 'trying', 'turkey', 'turkish', 'turks', 'turn', 'turned', 'type', 'types', 'understand', 'understanding', 'unfortunately', 'unit', 'united', 'universe', 'university', 'unix', 'unless', 'used', 'useful', 'usenet', 'user', 'users', 'uses', 'using', 'usually', 'valid', 'value', 'values', 'vancouver', 'various', 'vehicle', 'version', 'versions', 'video', 'view', 'voice', 'volume', 'wait', 'want', 'wanted', 'wants', 'washington', 'watch', 'water', 'ways', 'weapon', 'weapons', 'week', 'weeks', 'went', 'west', 'western', 'white', 'wide', 'widget', 'wife', 'willing', 'window', 'windows', 'wire', 'wish', 'woman', 'women', 'wonder', 'wondering', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worse', 'worth', 'write', 'writing', 'written', 'wrong', 'wrote', 'xterm', 'yeah', 'year', 'years', 'york', 'young']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\answl\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "print(len(terms))\n",
    "print(terms) # 1000개의 단어 피쳐들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b8396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:  ['like', 'know', 'people', 'think', 'good', 'time', 'thanks', 'make']\n",
      "Topic 2:  ['thanks', 'windows', 'card', 'drive', 'mail', 'file', 'advance', 'files']\n",
      "Topic 3:  ['game', 'team', 'year', 'games', 'season', 'players', 'good', 'play']\n",
      "Topic 4:  ['drive', 'scsi', 'disk', 'hard', 'card', 'drives', 'problem', 'controller']\n",
      "Topic 5:  ['windows', 'file', 'window', 'files', 'program', 'using', 'problem', 'running']\n",
      "Topic 6:  ['government', 'chip', 'mail', 'space', 'information', 'encryption', 'data', 'sale']\n",
      "Topic 7:  ['like', 'bike', 'know', 'chip', 'sounds', 'looks', 'look', 'sure']\n",
      "Topic 8:  ['card', 'sale', 'video', 'offer', 'monitor', 'price', 'jesus', 'condition']\n",
      "Topic 9:  ['know', 'card', 'chip', 'video', 'government', 'people', 'clipper', 'drivers']\n",
      "Topic 10:  ['good', 'know', 'time', 'bike', 'jesus', 'problem', 'work', 'want']\n",
      "Topic 11:  ['think', 'chip', 'good', 'thanks', 'clipper', 'need', 'encryption', 'mail']\n",
      "Topic 12:  ['thanks', 'right', 'problem', 'good', 'bike', 'time', 'window', 'people']\n",
      "Topic 13:  ['good', 'people', 'windows', 'know', 'file', 'sale', 'files', 'price']\n",
      "Topic 14:  ['space', 'think', 'know', 'nasa', 'problem', 'year', 'israel', 'time']\n",
      "Topic 15:  ['space', 'good', 'card', 'people', 'time', 'nasa', 'thanks', 'year']\n",
      "Topic 16:  ['people', 'problem', 'window', 'time', 'game', 'want', 'bike', 'using']\n",
      "Topic 17:  ['time', 'bike', 'right', 'windows', 'file', 'need', 'really', 'card']\n",
      "Topic 18:  ['time', 'problem', 'file', 'think', 'israel', 'long', 'mail', 'armenian']\n",
      "Topic 19:  ['file', 'need', 'card', 'files', 'problem', 'right', 'good', 'game']\n",
      "Topic 20:  ['problem', 'file', 'thanks', 'used', 'space', 'chip', 'sale', 'files']\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "components = svd_model.components_\n",
    "\n",
    "for index, topic in enumerate(components):\n",
    "    print(\"Topic %d: \" % (index+1), [terms[i] for i in topic.argsort()[:-n-1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9075ea47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,6,4,9])\n",
    "a.argsort() # 값들의 인덱스로 정렬! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2c862ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort() # 원본자체 변경 리스트 메소드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b003bcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 6, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07884d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 4, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-5:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd21d7e",
   "metadata": {},
   "source": [
    "# LSA의 한계\n",
    "\n",
    "- 문서에 포함된 단어가 \"가우시안 분포\"(정규분포)를 따라야만 LSA 적용 가능 \n",
    "- 문서 업데이트 시, 처음부터 다시 SVD 적용해줘야 하여 자원이 많이 소모됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
